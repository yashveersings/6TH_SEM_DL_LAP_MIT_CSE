{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh_8T6tJ63P1",
        "outputId": "09f3bbe1-a330-4de8-986b-0def7f737f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Original Model Train Loss: 2.3365, Test Accuracy: 0.0974\n",
            "Epoch 1: Modified Model Train Loss: 2.2979, Test Accuracy: 0.1432\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 64\n",
        "epochs = 3\n",
        "\n",
        "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
        "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "class CNNMnist(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNMnist, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2),\n",
        "            nn.Conv2d(128, 64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2)\n",
        "        )\n",
        "        self.classification_head = nn.Sequential(\n",
        "            nn.Linear(64, 20, bias=True),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(20, 10, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.net(x)\n",
        "        x = self.classification_head(features.view(x.size(0), -1))\n",
        "        return x\n",
        "\n",
        "class ModifiedCNNMnist(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedCNNMnist, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2),\n",
        "            nn.Conv2d(64, 32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2)\n",
        "        )\n",
        "        self.classification_head = nn.Sequential(\n",
        "            nn.Linear(32, 10, bias=True)  # Adjusted the number of output features to 10\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.net(x)\n",
        "        x = self.classification_head(features.view(features.size(0), -1))\n",
        "        return x\n",
        "\n",
        "def train_one_epoch(model, train_loader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "    return accuracy\n",
        "\n",
        "original_model = CNNMnist().to(device)\n",
        "modified_model = ModifiedCNNMnist().to(device)\n",
        "\n",
        "optimizer_original = torch.optim.SGD(original_model.parameters(), lr=0.001)\n",
        "optimizer_modified = torch.optim.SGD(modified_model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "accuracy_original = []\n",
        "accuracy_modified = []\n",
        "percentage_drop = []\n",
        "\n",
        "original_params = sum(p.numel() for p in original_model.parameters())\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_one_epoch(original_model, train_loader, optimizer_original, loss_fn)\n",
        "    accuracy = test_model(original_model, test_loader)\n",
        "    accuracy_original.append(accuracy)\n",
        "    print(f\"Epoch {epoch+1}: Original Model Train Loss: {train_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    train_loss = train_one_epoch(modified_model, train_loader, optimizer_modified, loss_fn)\n",
        "    accuracy = test_model(modified_model, test_loader)\n",
        "    accuracy_modified.append(accuracy)\n",
        "    print(f\"Epoch {epoch+1}: Modified Model Train Loss: {train_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    if epoch > 0:\n",
        "        percentage_drop.append((original_params - sum(p.numel() for p in modified_model.parameters())) / original_params * 100)\n",
        "\n",
        "plt.plot(percentage_drop, accuracy_original, label=\"Original Model\")\n",
        "plt.plot(percentage_drop, accuracy_modified, label=\"Modified Model\")\n",
        "plt.xlabel(\"Percentage Drop in Parameters\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Percentage Drop in Parameters vs Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}